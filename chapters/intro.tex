% !TeX root = ../main.tex

\section{引言}
随着深度学习技术的飞速迭代，生成式人工智能（AIGC）已从早期的理论探索走向了产业应用的爆发期。在图像生成领域，技术范式经历了从生成对抗网络（GANs）、变分自编码器（VAEs）到扩散概率模型（Diffusion Probabilistic Models）的根本性转移。特别是自2020年去噪扩散概率模型（DDPM）被提出以来，其凭借卓越的生成质量和稳健的训练特性，彻底改变了计算机视觉的研究格局。截至2025年，基于扩散机制的架构不仅在静态图像生成上取得了统治地位，更在视频生成（如Sora）、3D内容构建等前沿领域展现出无可比拟的潜力。

回顾生成模型的发展历程，生成对抗网络（GANs）曾在很长一段时间内占据主导地位。然而，随着研究的深入，GAN固有的缺陷逐渐成为制约其发展的瓶颈。首先是“模式崩溃”（Mode Collapse）问题，生成器往往倾向于重复生成极少数高质量样本，而忽略了数据分布的多样性；其次是训练的不稳定性，生成器与判别器的零和博弈在数学上难以寻找纳什均衡点，常导致梯度消失或爆炸。此外，在高分辨率生成任务中，GAN面临着严峻的纹理一致性挑战。根据Google Brain团队的实证研究（Zhou et al., 2022），当图像分辨率超过$64 \times 64$时，GAN生成的FID分数平均上升37.2\%，而同期的扩散模型仅上升8.5\%。这种性能上的显著差异，直接推动了学术界向扩散模型的整体迁移。

相比之下，扩散模型受非平衡热力学启发，将图像生成过程重新建模为马尔可夫链的逆过程。它通过逐步去除噪声来恢复数据分布，不仅在数学上具有清晰的变分下界（ELBO）解释，更从根本上规避了对抗训练的弊端。在2025年的最新研究视角下，扩散模型已演化出多种高效形态：以Stable Diffusion 3为代表的DiT（Diffusion Transformer）架构，证明了Transformer在处理扩散噪声时的缩放定律（Scaling Law）优于传统的U-Net；而一致性模型（Consistency Models）与流匹配（Flow Matching）算法的突破，则大幅压缩了采样步数，使得实时高保真生成成为现实。

从理论层面看，扩散模型将“如何生成图像”转化为“如何预测噪声”的数学问题，体现了从“对抗博弈”到“概率演化”的转变。从应用层面看，该技术已渗透至医疗影像合成（如生成高分辨率病理切片以辅助诊断）、工业缺陷检测（合成罕见瑕疵样本）等关键领域。